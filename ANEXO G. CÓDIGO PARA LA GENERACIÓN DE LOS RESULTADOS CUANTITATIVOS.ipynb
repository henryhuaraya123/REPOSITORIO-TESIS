{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURACIÓN INICIAL ---\n",
    "\n",
    "\n",
    "# Instalación de librerías (si es necesario)\n",
    "!pip install --quiet openpyxl\n",
    "!pip install --quiet xlsxwriter\n",
    "\n",
    "\n",
    "# Montar Google Drive (Sigue las instrucciones que aparecen al ejecutar)\n",
    "from google.colab import drive\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, f1_score, precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# --- 2. CONFIGURACIÓN DE RUTAS (AJUSTADAS) ---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ruta a la carpeta principal donde se encuentra 'MODELOS'\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/'\n",
    "\n",
    "\n",
    "# Ruta a la carpeta que contiene las carpetas de los modelos (ej: DENSENET_201, INCEPTION, etc.)\n",
    "MODELS_DIR = os.path.join(DRIVE_ROOT, 'MODELOS')\n",
    "\n",
    "\n",
    "# Ruta a la carpeta TEST (donde están las 12 carpetas de especies)\n",
    "# Asumo que esta es la ruta de la imagen original. Si no es así, AJÚSTALA.\n",
    "TEST_DATA_PATH = os.path.join(DRIVE_ROOT, 'plantas_dataset_v2/dataset_split_anidado/test')\n",
    "\n",
    "\n",
    "# Carpeta para guardar los resultados finales de la evaluación\n",
    "SAVE_RESULTS_PATH = os.path.join(DRIVE_ROOT, 'Evaluation_Results')\n",
    "\n",
    "\n",
    "# Crear la carpeta de resultados si no existe\n",
    "if not os.path.exists(SAVE_RESULTS_PATH):\n",
    "    os.makedirs(SAVE_RESULTS_PATH)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "\n",
    "# Parámetros generales\n",
    "num_classes = 12\n",
    "batch_size = 8\n",
    "feature_extract = False # Debe coincidir con el entrenamiento\n",
    "\n",
    "\n",
    "# Lista de modelos a evaluar, con sus nombres de carpeta exactos para cargar los pesos\n",
    "MODELS_TO_EVAL = [\n",
    "    {\"name\": \"VGG11-BN\", \"folder\": \"VGG11_BN\"},\n",
    "    {\"name\": \"DenseNet-201\", \"folder\": \"DENSENET_201\"},\n",
    "    {\"name\": \"ResNet-101\", \"folder\": \"RESNET_101\"},\n",
    "    {\"name\": \"MobileNetV2\", \"folder\": \"MOBILENETV2\"},\n",
    "    {\"name\": \"inception\", \"folder\": \"INCEPTION\"},\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"\\nModelos listos para evaluación en: {MODELS_DIR}\")\n",
    "print(f\"Datos de prueba cargados desde: {TEST_DATA_PATH}\")\n",
    "# --- 3. FUNCIONES DE TU CÓDIGO ORIGINAL (Asegúrate de que sean idénticas) ---\n",
    "\n",
    "\n",
    "# Función Auxiliar para Fine-Tuning\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "# Función Clave: Inicialización de Modelos con Tamaños Óptimos\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    from torchvision import models\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "\n",
    "    if model_name == \"VGG11-BN\":\n",
    "        \"\"\" VGG11_bn (Input 224) \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"DenseNet-201\":\n",
    "        \"\"\" DenseNet-201 (Input 224) \"\"\"\n",
    "        model_ft = models.densenet201(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"ResNet-101\":\n",
    "        \"\"\" ResNet-101 (Input 224) \"\"\"\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"MobileNetV2\":\n",
    "        \"\"\" MobileNetV2 (Input 224) \"\"\"\n",
    "        model_ft = models.mobilenet_v2(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception V3 (Input 299) \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained, aux_logits=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.AuxLogits.fc = nn.Linear(model_ft.AuxLogits.fc.in_features, num_classes)\n",
    "        model_ft.fc = nn.Linear(model_ft.fc.in_features, num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Nombre de modelo inválido.\")\n",
    "        return None, 0\n",
    "\n",
    "\n",
    "    return model_ft, input_size\n",
    "# --- 4. FUNCIÓN DE EVALUACIÓN Y GENERACIÓN DE GRÁFICOS ---\n",
    "\n",
    "\n",
    "def evaluate_model_and_plot(model, dataloader, model_name, class_names):\n",
    "    \"\"\"Evalúa el modelo, calcula métricas detalladas y genera gráficos.\"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "\n",
    "    print(f\"Evaluando {model_name} en {len(dataloader.dataset)} imágenes...\")\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            if isinstance(outputs, tuple):  # Manejo específico para Inception en evaluación\n",
    "                outputs = outputs[0]\n",
    "\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "    # --- Métrica General ---\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1_micro = f1_score(all_labels, all_preds, average='micro', zero_division=0)\n",
    "    print(f\"\\n--- Resultados Generales de {model_name} en TEST ---\")\n",
    "    print(f\"Accuracy General: {acc:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Métricas por Clase (DataFrame) ---\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True, zero_division=0)\n",
    "    species_data = []\n",
    "    for class_name, metrics in report.items():\n",
    "        if class_name in class_names:\n",
    "            species_data.append({\n",
    "                'Model': model_name,\n",
    "                'Species': class_name,\n",
    "                'Precision': metrics['precision'],\n",
    "                'Recall': metrics['recall'],\n",
    "                'F1_Score': metrics['f1-score'],\n",
    "                'Support': metrics['support']\n",
    "            })\n",
    "    species_df = pd.DataFrame(species_data)\n",
    "\n",
    "\n",
    "    # --- Matriz de Confusión (DataFrame) ---\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    cm_df.insert(0, 'Model', model_name)\n",
    "\n",
    "\n",
    "    # --- Generación de Gráficos ---\n",
    "\n",
    "\n",
    "    # 1. Matriz de Confusión\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Matriz de Confusión: {model_name}\\nAcc: {acc:.4f}')\n",
    "    plt.ylabel('Etiqueta Real (True Label)')\n",
    "    plt.xlabel('Predicción (Predicted Label)')\n",
    "    plt.savefig(os.path.join(SAVE_RESULTS_PATH, f'CM_{model_name.replace(\"-\", \"_\")}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Precisión por Especie (Gráfico de Barras)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Species', y='Precision', data=species_df, palette='viridis')\n",
    "    plt.title(f'Precisión por Especie (TEST): {model_name}')\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.xlabel('Especie')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_RESULTS_PATH, f'Precision_by_Species_{model_name.replace(\"-\", \"_\")}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return acc, f1_micro, species_df, cm_df\n",
    "\n",
    "\n",
    "# --- 5. BUCLE PRINCIPAL DE EVALUACIÓN ---\n",
    "\n",
    "\n",
    "ALL_EVAL_SPECIES_RESULTS = []\n",
    "ALL_EVAL_CMS = []\n",
    "ALL_EVAL_GENERAL_RESULTS = []\n",
    "\n",
    "\n",
    "for config in MODELS_TO_EVAL:\n",
    "    model_name = config['name']\n",
    "    folder_name = config['folder']\n",
    "\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" INICIANDO EVALUACIÓN DE: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "\n",
    "    # 1. Definir Input Size y Modelos\n",
    "    # use_pretrained=False aquí solo garantiza la estructura, ya que cargaremos los pesos entrenados\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "    if model_ft is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 2. Cargar Pesos del Mejor Modelo\n",
    "    weights_path = os.path.join(MODELS_DIR, folder_name, 'best.pt')\n",
    "\n",
    "\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"ADVERTENCIA: No se encontraron pesos en {weights_path}. Saltando {model_name}.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(weights_path, map_location=device)\n",
    "        model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model_ft.to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR al cargar el estado del modelo {model_name}: {e}. Saltando.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 3. Transformaciones para el conjunto de prueba\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.255])\n",
    "    ])\n",
    "\n",
    "\n",
    "    # 4. DataLoader de Prueba\n",
    "    try:\n",
    "        test_dataset = datasets.ImageFolder(TEST_DATA_PATH, test_transforms)\n",
    "        class_names = test_dataset.classes\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        print(f\"Clases detectadas: {class_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR al cargar el conjunto de datos de prueba desde {TEST_DATA_PATH}: {e}. Saltando.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 5. Evaluación\n",
    "    acc, f1_micro, species_df, cm_df = evaluate_model_and_plot(model_ft, test_dataloader, model_name, class_names)\n",
    "\n",
    "\n",
    "    # 6. Acumular Resultados\n",
    "    ALL_EVAL_GENERAL_RESULTS.append(pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'Test_Acc': acc,\n",
    "        'Test_F1_Micro': f1_micro\n",
    "    }]))\n",
    "    ALL_EVAL_SPECIES_RESULTS.append(species_df)\n",
    "    ALL_EVAL_CMS.append(cm_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 6. EXPORTAR RESULTADOS FINALES ---\n",
    "\n",
    "\n",
    "# Resultados generales (Accuracy y F1)\n",
    "final_eval_general_df = pd.concat(ALL_EVAL_GENERAL_RESULTS, ignore_index=True)\n",
    "final_eval_general_df.to_csv(os.path.join(SAVE_RESULTS_PATH, 'Final_Test_General_Metrics.csv'), index=False)\n",
    "\n",
    "\n",
    "# Resultados detallados por especie\n",
    "final_eval_species_df = pd.concat(ALL_EVAL_SPECIES_RESULTS, ignore_index=True)\n",
    "final_eval_species_df.to_csv(os.path.join(SAVE_RESULTS_PATH, 'Final_Test_Species_Metrics.csv'), index=False)\n",
    "\n",
    "\n",
    "# Matriz de Confusión (Excel)\n",
    "with pd.ExcelWriter(os.path.join(SAVE_RESULTS_PATH, 'Final_Test_Confusion_Matrices.xlsx'), engine='xlsxwriter') as writer:\n",
    "    for cm_df in ALL_EVAL_CMS:\n",
    "        if not cm_df.empty:\n",
    "            model_name_safe = cm_df['Model'].iloc[0].replace('-', '_')\n",
    "            cm_df_to_save = cm_df.drop(columns=['Model'])\n",
    "            cm_df_to_save.to_excel(writer, sheet_name=model_name_safe)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*50)\n",
    "print(\" Evaluación de Prueba Finalizada con Éxito\")\n",
    "print(f\" Resultados guardados en Drive en la carpeta: {SAVE_RESULTS_PATH}\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
