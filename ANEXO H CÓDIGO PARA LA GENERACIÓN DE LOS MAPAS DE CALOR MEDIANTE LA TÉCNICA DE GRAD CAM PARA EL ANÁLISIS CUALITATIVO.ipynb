{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4036f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SCRIPT 1: PREPARACIÓN DE MUESTRAS ---\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Montar Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "# Ruta raíz de tu Drive\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/'\n",
    "# Ruta a tu carpeta TEST (donde están las 12 especies)\n",
    "TEST_DATA_PATH = os.path.join(DRIVE_ROOT, 'plantas_dataset_v2/dataset_split_anidado/test')\n",
    "# Nueva carpeta donde se guardarán las 2 imágenes de muestra por especie\n",
    "GRADCAM_SAMPLES_PATH = os.path.join(DRIVE_ROOT, 'GradCAM_Samples')\n",
    "\n",
    "\n",
    "# Crear carpeta de muestras, eliminando la anterior si existe para empezar de cero\n",
    "if os.path.exists(GRADCAM_SAMPLES_PATH):\n",
    "    shutil.rmtree(GRADCAM_SAMPLES_PATH)\n",
    "Path(GRADCAM_SAMPLES_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "NUM_SAMPLES_PER_CLASS = 2 # Número de imágenes a seleccionar por especie\n",
    "\n",
    "\n",
    "# --- LÓGICA DE EXTRACCIÓN ---\n",
    "\n",
    "\n",
    "# Obtener nombres de las especies\n",
    "species_folders = [d for d in os.listdir(TEST_DATA_PATH) if os.path.isdir(os.path.join(TEST_DATA_PATH, d))]\n",
    "\n",
    "\n",
    "if not species_folders:\n",
    "    print(f\"ERROR: No se encontraron subcarpetas (especies) en {TEST_DATA_PATH}. Verifica la ruta.\")\n",
    "else:\n",
    "    print(f\"Iniciando selección de {NUM_SAMPLES_PER_CLASS} muestras de {len(species_folders)} especies.\")\n",
    "\n",
    "\n",
    "    for species_name in species_folders:\n",
    "        species_dir = os.path.join(TEST_DATA_PATH, species_name)\n",
    "        images = [f for f in os.listdir(species_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "\n",
    "        if len(images) < NUM_SAMPLES_PER_CLASS:\n",
    "            print(f\"Advertencia: La especie {species_name} solo tiene {len(images)} imágenes.\")\n",
    "            selected_images = images\n",
    "        else:\n",
    "            selected_images = random.sample(images, NUM_SAMPLES_PER_CLASS)\n",
    "\n",
    "\n",
    "        # Crear subcarpeta en GradCAM_Samples\n",
    "        target_species_dir = os.path.join(GRADCAM_SAMPLES_PATH, species_name)\n",
    "        Path(target_species_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "        # Copiar imágenes seleccionadas\n",
    "        for img_name in selected_images:\n",
    "            source_path = os.path.join(species_dir, img_name)\n",
    "            target_path = os.path.join(target_species_dir, img_name)\n",
    "            shutil.copy(source_path, target_path)\n",
    "\n",
    "\n",
    "    print(\"\\n Extracción de muestras completada.\")\n",
    "    print(f\"Imágenes guardadas en: {GRADCAM_SAMPLES_PATH}\")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/'\n",
    "MODELS_DIR = os.path.join(DRIVE_ROOT, 'MODELOS')\n",
    "GRADCAM_SAMPLES_PATH = os.path.join(DRIVE_ROOT, 'GradCAM_Samples')\n",
    "GRADCAM_OUTPUT_PATH = os.path.join(DRIVE_ROOT, 'GRADCAM_RESULTS') # Carpeta de resultados\n",
    "Path(GRADCAM_OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Parámetros de Grad-CAM y modelos ---\n",
    "num_classes = 12\n",
    "feature_extract = False\n",
    "\n",
    "\n",
    "# Mapeo de modelos y sus últimas capas convolucionales (target_layer)\n",
    "MODELS_CONFIG = {\n",
    "    'VGG11-BN':    {'func': models.vgg11_bn,      'folder': 'VGG11_BN',     'target_layer': 'features[-1]'}, # Última capa ReLU del último bloque\n",
    "    'DenseNet-201':{'func': models.densenet201,   'folder': 'DENSENET_201', 'target_layer': 'features.denseblock4'}, # Último bloque denso\n",
    "    'ResNet-101':  {'func': models.resnet101,     'folder': 'RESNET_101',   'target_layer': 'layer4'}, # Última capa de bloques\n",
    "    'MobileNetV2': {'func': models.mobilenet_v2,  'folder': 'MOBILENETV2',  'target_layer': 'features[18]'}, # Última capa convolucional antes del pool\n",
    "    'Inception':   {'func': models.inception_v3,  'folder': 'INCEPTION',    'target_layer': 'Mixed_7c'}, # Último bloque mixto\n",
    "}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Funciones auxiliares de tu código ---\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "  if feature_extracting:\n",
    "    for param in model.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "  # Tu función de inicialización modificada para este script (simplificada y ajustada para Grad-CAM)\n",
    "  from torchvision import models\n",
    "  model_ft = None\n",
    "  input_size = 0\n",
    "\n",
    "\n",
    "  config = MODELS_CONFIG.get(model_name)\n",
    "  if not config:\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "  model_func = config['func']\n",
    "\n",
    "\n",
    "  # Inicializa el modelo (con pretrained=True si se desea cargar una estructura estándar)\n",
    "  model_ft = model_func(weights=None) # Cargar solo la estructura sin pesos de ImageNet\n",
    "\n",
    "\n",
    "  # Ajusta la capa final según tu arquitectura original\n",
    "  set_parameter_requires_grad(model_ft, feature_extract)\n",
    "  try:\n",
    "    if model_name == \"VGG11-BN\":\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"DenseNet-201\":\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"ResNet-101\":\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"MobileNetV2\":\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"Inception\":\n",
    "        # Inception V3 requiere aux_logits=True para inicializar correctamente la estructura\n",
    "        model_ft = models.inception_v3(weights=None, aux_logits=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.AuxLogits.fc = nn.Linear(model_ft.AuxLogits.fc.in_features, num_classes)\n",
    "        model_ft.fc = nn.Linear(model_ft.fc.in_features, num_classes)\n",
    "        input_size = 299\n",
    "  except Exception as e:\n",
    "    print(f\"Error al ajustar capa final de {model_name}: {e}\")\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "  return model_ft, input_size\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, img_size):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((img_size, img_size)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  ])\n",
    "  image = Image.open(image_path).convert(\"RGB\")\n",
    "  tensor = transform(image).unsqueeze(0)\n",
    "  return tensor, image\n",
    "\n",
    "\n",
    "# --- BUCLE PRINCIPAL DE GRAD-CAM ---\n",
    "\n",
    "\n",
    "# Obtener todas las imágenes de muestra\n",
    "image_paths = glob.glob(os.path.join(GRADCAM_SAMPLES_PATH, '*', '*'))\n",
    "if not image_paths:\n",
    "    print(f\" No se encontraron imágenes en {GRADCAM_SAMPLES_PATH}. Ejecuta el Script 1 primero.\")\n",
    "else:\n",
    "    print(f\"\\nIniciando Grad-CAM para {len(image_paths)} imágenes de muestra...\")\n",
    "\n",
    "\n",
    "    # DataFrame para resultados (opcional para un agente externo)\n",
    "    gradcam_results = []\n",
    "\n",
    "\n",
    "    for model_name, config in MODELS_CONFIG.items():\n",
    "        print(f\"\\n==================================================\")\n",
    "        print(f\"=== Generando Grad-CAM: {model_name} ===\")\n",
    "        print(f\"==================================================\")\n",
    "\n",
    "\n",
    "        model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "        if model_ft is None:\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Cargar pesos entrenados del mejor modelo\n",
    "        weights_path = os.path.join(MODELS_DIR, config['folder'], 'best.pt')\n",
    "        try:\n",
    "            checkpoint = torch.load(weights_path, map_location=device)\n",
    "            model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(f\"Pesos cargados exitosamente desde: {weights_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\" ERROR al cargar pesos para {model_name}: {e}. Saltando este modelo.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        model_ft.eval()\n",
    "        model_ft.to(device)\n",
    "\n",
    "\n",
    "        # Habilitar gradientes en todas las capas para Grad-CAM (es temporal para la inferencia)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "        # Inicializar el extractor GradCAM\n",
    "        try:\n",
    "            cam_extractor = GradCAM(model_ft, target_layer=config['target_layer'])\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: No se pudo inicializar GradCAM para la capa {config['target_layer']}: {e}. Saltando.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            species_name = Path(image_path).parent.name\n",
    "            image_filename = Path(image_path).name\n",
    "\n",
    "\n",
    "            # Preprocesar imagen y realizar forward pass\n",
    "            input_tensor, original_img = preprocess_image(image_path, input_size)\n",
    "            input_tensor = input_tensor.to(device)\n",
    "\n",
    "\n",
    "            # Limpiar caché de gradientes por si acaso\n",
    "            model_ft.zero_grad()\n",
    "\n",
    "\n",
    "            out = model_ft(input_tensor)\n",
    "\n",
    "\n",
    "            # Manejo específico para Inception en la inferencia\n",
    "            if isinstance(out, tuple):\n",
    "                out = out[0]\n",
    "\n",
    "\n",
    "            pred_logits = out.cpu()\n",
    "            pred_class_idx = pred_logits.argmax(dim=1).item()\n",
    "            pred_confidence = torch.nn.functional.softmax(pred_logits, dim=1).max().item()\n",
    "\n",
    "\n",
    "            # Asumiendo que el nombre de la carpeta (species_name) es la etiqueta correcta\n",
    "            # Necesitamos mapear el índice predicho de vuelta al nombre de la clase\n",
    "\n",
    "\n",
    "            # --- Tarea Pendiente: Obtener mapeo de clases para el nombre real ---\n",
    "            # Si se usó ImageFolder para el entrenamiento, se necesita el mapeo idx_to_class\n",
    "            # Asumo que el mapeo se obtiene si tienes acceso al DataLoader que usaste para entrenar.\n",
    "            # Como no lo tenemos aquí, lo simularemos si solo tienes 12 carpetas:\n",
    "            # Puedes reemplazar 'Clase Predicha' por el nombre real de la clase\n",
    "\n",
    "\n",
    "            # Por ahora usaremos el índice predicho como referencia:\n",
    "            predicted_class_name = f\"Index_{pred_class_idx}\"\n",
    "            # --- Fin Tarea Pendiente ---\n",
    "\n",
    "\n",
    "            # Extraer Grad-CAM map\n",
    "            # cam_extractor retorna una lista de tensores (uno por capa objetivo)\n",
    "            activation_map = cam_extractor(pred_class_idx, out)[0]\n",
    "\n",
    "\n",
    "            # Redimensionar el mapa a las dimensiones de la imagen de entrada (Heatmap)\n",
    "            activation_map = transforms.Resize(input_size)(activation_map.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "\n",
    "            # Superponer el mapa en la imagen original\n",
    "            # Se convierte a numpy y se usa 'F' (float) para overlay_mask\n",
    "            mask_np = activation_map.cpu().numpy()\n",
    "            result_img = overlay_mask(original_img, Image.fromarray(mask_np, mode='F'), alpha=0.5)\n",
    "\n",
    "\n",
    "            # --- Visualización y Guardado ---\n",
    "            plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(original_img)\n",
    "            plt.title(f\"Original: {species_name}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(result_img)\n",
    "            plt.title(f\"{model_name} - Pred: {predicted_class_name} ({pred_confidence:.2f})\")\n",
    "            plt.axis('off')\n",
    "\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "\n",
    "            # Guardar en la carpeta de resultados\n",
    "            output_dir = os.path.join(GRADCAM_OUTPUT_PATH, model_name)\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            save_filename = f\"{species_name}_{Path(image_filename).stem}_GradCAM.png\"\n",
    "            plt.savefig(os.path.join(output_dir, save_filename), dpi=300)\n",
    "            plt.close() # Cierra la figura para evitar sobrecarga de memoria\n",
    "\n",
    "\n",
    "            # Acumular resultados para el agente\n",
    "            gradcam_results.append({\n",
    "                'Model': model_name,\n",
    "                'Species': species_name,\n",
    "                'Filename': image_filename,\n",
    "                'Predicted_Index': pred_class_idx,\n",
    "                'Confidence': pred_confidence,\n",
    "                'GradCAM_Path': os.path.join(output_dir, save_filename)\n",
    "            })\n",
    "\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"   Procesadas {i+1} de {len(image_paths)} imágenes para {model_name}.\")\n",
    "\n",
    "\n",
    "    print(\"\\n Generación de Grad-CAMs completada.\")\n",
    "    print(f\"Resultados guardados en la carpeta: {GRADCAM_OUTPUT_PATH} (una subcarpeta por modelo).\")\n",
    "\n",
    "\n",
    "    # Exportar Dataframe de resultados para el agente\n",
    "    final_gradcam_df = pd.DataFrame(gradcam_results)\n",
    "    final_gradcam_df.to_csv(os.path.join(GRADCAM_OUTPUT_PATH, 'GradCAM_Index_Results.csv'), index=False)\n",
    "\n",
    "\n",
    "    # Puedes agregar este DataFrame a tu agente de Grad-CAM para que analice los patrones.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
